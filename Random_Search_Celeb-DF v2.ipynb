{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 7\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load the optimized model\n",
    "loaded_model = joblib.load('/content/drive/MyDrive/model_randomsearch.pkl')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "base_path_new = '/content/drive/MyDrive/Celeb-DF-v2'\n",
    "\n",
    "\n",
    "real_path_new = os.path.join(base_path_new, 'Celeb-real')\n",
    "fake_path_new = os.path.join(base_path_new, 'Celeb-synthesis')\n",
    "\n",
    "\n",
    "fake_video_files_new = [os.path.join(fake_path_new, file) for file in os.listdir(fake_path_new) if file.endswith('.mp4')]\n",
    "real_video_files_new = [os.path.join(real_path_new, file) for file in os.listdir(real_path_new) if file.endswith('.mp4')]\n",
    "\n",
    "\n",
    "real_labels_new = ['echt'] * len(real_video_files_new)\n",
    "fake_labels_new = ['df'] * len(fake_video_files_new)\n",
    "\n",
    "\n",
    "file_paths_new = real_video_files_new + fake_video_files_new\n",
    "labels_new = real_labels_new + fake_labels_new\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "\n",
    "feature_extraction_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "\n",
    "def load_and_preprocess_video_new(file_path, label, desired_num_frames=16):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    frames = []\n",
    "\n",
    "    \n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for _ in tqdm(range(min(num_frames, desired_num_frames)), desc=f\"Processing {os.path.basename(file_path)}\", unit=\" frame\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "        frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        return None, label\n",
    "\n",
    "    if len(frames) < desired_num_frames:\n",
    "        frames = np.concatenate([frames] * (desired_num_frames // len(frames) + 1), axis=0)\n",
    "        frames = frames[:desired_num_frames]\n",
    "    elif len(frames) > desired_num_frames:\n",
    "        frames = frames[:desired_num_frames]\n",
    "\n",
    "    frames = np.vstack(frames)  \n",
    "    return frames, label\n",
    "\n",
    "# Use the feature extraction model to extract features from videos in the new dataset\n",
    "new_dataset_features = []\n",
    "\n",
    "for file_path, label in zip(file_paths_new, labels_new):\n",
    "    frames, _ = load_and_preprocess_video_new(file_path, label)\n",
    "    if frames is not None:\n",
    "        features = feature_extraction_model.predict(frames)\n",
    "        new_dataset_features.append(features)\n",
    "\n",
    "# Convert the extracted features to numpy arrays for the new dataset\n",
    "X_new_dataset_features = np.array(new_dataset_features).reshape(len(new_dataset_features), -1)\n",
    "\n",
    "# Predictions on the new dataset using the loaded model\n",
    "y_new_dataset_pred = loaded_model.predict(X_new_dataset_features)\n",
    "\n",
    "# Calculate accuracy on the new dataset\n",
    "accuracy_test = accuracy_score(labels_new, y_new_dataset_pred)\n",
    "\n",
    "# Calculate precision on the new dataset\n",
    "precision_test = precision_score(labels_new, y_new_dataset_pred, pos_label='df')\n",
    "\n",
    "# Calculate ROC AUC on the new dataset\n",
    "y_new_dataset_proba = loaded_model.predict_proba(X_new_dataset_features)[:, 1]\n",
    "roc_auc_test = roc_auc_score(labels_new, y_new_dataset_proba)\n",
    "\n",
    "# Calculate recall on the new dataset\n",
    "recall_test = recall_score(labels_new, y_new_dataset_pred, pos_label='df')\n",
    "\n",
    "# Calculate F1-score on the new dataset\n",
    "f1_test = f1_score(labels_new, y_new_dataset_pred, pos_label='df')\n",
    "\n",
    "# Create and visualize a confusion matrix heatmap for the new dataset\n",
    "cm_test = confusion_matrix(labels_new, y_new_dataset_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['echt', 'df'], yticklabels=['echt', 'df'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap for the New Dataset')\n",
    "plt.show()\n",
    "\n",
    "# Display results on the new dataset\n",
    "print(f\"Accuracy on the New Dataset: {accuracy_test:.2f}\")\n",
    "print(f\"Precision on the New Dataset: {precision_test:.2f}\")\n",
    "print(f\"ROC AUC on the New Dataset: {roc_auc_test:.2f}\")\n",
    "print(f\"Recall on the New Dataset: {recall_test:.2f}\")\n",
    "print(f\"F1-score on the New Dataset: {f1_test:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
