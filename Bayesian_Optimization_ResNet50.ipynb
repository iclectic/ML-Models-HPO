{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load('/content/drive/MyDrive/model_filename_original_resnet.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import joblib  # Import joblib for model saving\n",
    "import seaborn as sns  # Import seaborn for visualization\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for visualization\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "#batch size\n",
    "batch_size = 32\n",
    "\n",
    "#base folder path to your dataset\n",
    "base_path = '/content/drive/MyDrive/Celeb-DFF'\n",
    "\n",
    "# subfolder paths for real and fake videos\n",
    "real_path_1 = os.path.join(base_path, 'Celeb-real')\n",
    "fake_path = os.path.join(base_path, 'Celeb-synthesis')\n",
    "\n",
    "#file paths for real and fake videos\n",
    "fake_video_files = [os.path.join(fake_path, file) for file in os.listdir(fake_path) if file.endswith('.mp4')]\n",
    "real_video_files = [os.path.join(real_path_1, file) for file in os.listdir(real_path_1) if file.endswith('.mp4')]\n",
    "\n",
    "#labels\n",
    "real_labels = ['echt'] * len(real_video_files)\n",
    "fake_labels = ['df'] * len(fake_video_files)\n",
    "\n",
    "\n",
    "file_paths = real_video_files + fake_video_files\n",
    "labels = real_labels + fake_labels\n",
    "\n",
    "#dataset is split into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(file_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#Pretrained ResNet-50 model loaded with weights from ImageNet\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "#global average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "#final feature extraction model\n",
    "feature_extraction_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Function to load and preprocess video frames with tqdm progress bars\n",
    "def load_and_preprocess_video(file_path, label, desired_num_frames=16):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    frames = []\n",
    "\n",
    "    # Read frames from the video\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for _ in tqdm(range(min(num_frames, desired_num_frames)), desc=f\"Processing {os.path.basename(file_path)}\", unit=\" frame\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize the frame to match ResNet-50 input size\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        return None, label\n",
    "\n",
    "\n",
    "    if len(frames) < desired_num_frames:\n",
    "        frames = np.concatenate([frames] * (desired_num_frames // len(frames) + 1), axis=0)\n",
    "        frames = frames[:desired_num_frames]\n",
    "    elif len(frames) > desired_num_frames:\n",
    "        frames = frames[:desired_num_frames]\n",
    "\n",
    "    frames = np.vstack(frames)\n",
    "    return frames, label\n",
    "\n",
    "\n",
    "train_features = []\n",
    "val_features = []\n",
    "\n",
    "for file_path, label in zip(X_train, y_train):\n",
    "    frames, _ = load_and_preprocess_video(file_path, label)\n",
    "    if frames is not None:\n",
    "        features = feature_extraction_model.predict(frames)\n",
    "        train_features.append(features)\n",
    "\n",
    "for file_path, label in zip(X_val, y_val):\n",
    "    frames, _ = load_and_preprocess_video(file_path, label)\n",
    "    if frames is not None:\n",
    "        features = feature_extraction_model.predict(frames)\n",
    "        val_features.append(features)\n",
    "\n",
    "# extracted features converted to numpy arrays\n",
    "X_train_features = np.array(train_features).reshape(len(train_features), -1)\n",
    "X_val_features = np.array(val_features).reshape(len(val_features), -1)\n",
    "\n",
    "# parameter space for Bayesian Optimization\n",
    "param_space = {\n",
    "    'C': (0.001, 100.0, 'log-uniform'),  # Adjust the range as needed\n",
    "    'solver': ['sag', 'liblinear'],  # Use 'sag' and 'liblinear' solvers\n",
    "}\n",
    "\n",
    "# logistic regression classifier is initialized at this point\n",
    "classifier = LogisticRegression(penalty='l2', max_iter=1000, random_state=42) \n",
    "\n",
    "# BayesianSearchCV initialization with the specified parameter space\n",
    "bayesian_search = BayesSearchCV(\n",
    "    classifier,\n",
    "    param_space,\n",
    "    n_iter=50,  \n",
    "    cv=5,  \n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "bayesian_search.fit(X_train_features, y_train)\n",
    "\n",
    "# Save the optimized model to your Google Drive directory\n",
    "joblib.dump(bayesian_search.best_estimator_, '/content/drive/MyDrive/baye_optimized_ResNet50_model.pkl')\n",
    "\n",
    "# Predictions on validation data using the best estimator from Bayesian search\n",
    "y_val_pred = bayesian_search.best_estimator_.predict(X_val_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_val, y_val_pred, pos_label='df')\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_val_proba = bayesian_search.best_estimator_.predict_proba(X_val_features)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_val, y_val_pred, pos_label='df')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_val, y_val_pred, pos_label='df')\n",
    "\n",
    "# Create and visualize a confusion matrix heatmap\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['echt', 'df'], yticklabels=['echt', 'df'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Display metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: 0.73\n",
    "# Precision: 0.70\n",
    "# ROC AUC: 0.71\n",
    "# Recall: 0.91\n",
    "# F1-score: 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
